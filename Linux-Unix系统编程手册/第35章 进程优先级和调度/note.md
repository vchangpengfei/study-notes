# 进程优先级(nice值)
调度进程使用 CPU 的默认模型是循环时间共享。
在这种模型中，每个进程轮流使用 CPU 一段时间，这段时间被称为时间片或量子。循环时间
共享满足了交互式多任务系统的两个重要需求。
- 公平性：每个进程都有机会用到 CPU。 
- 响应度：一个进程在使用 CPU 之前无需等待太长的时间。

在循环时间共享算法中，进程无法直接控制何时使用 CPU 以及使用 CPU 的时间。

非特权进程只能
降低自己的优先级，即赋一个大于默认值 0 的
nice 值。这样做之后它们就对其他进程“友好（nice）”了，这个特性的名称也由此而来。
```
//获取优先级
int getpriority(int which,id_t who)
设置优先级
int setpriority(int which,id_t who,int prio)
```
which有三种选项
PRIO_PROCESS
> who 是要设置的进程id

PRIO_PGRP
> who 是要设置的groupid

PRIO_USER
> who 是要设置的userid

# 实时进程调度概述

实时进程调度要求更加严格
1. 为外部输入提供担保最大响应时间。 
> 如交通导航，如果慢可能会导致灾难。
> 所以内核需提供工具让高优先级的进程快速获取cpu控制权，抢占当前运行的所有进程
> 一些时间关键的应用程序可能需要采取其他措施来避免不可接受的延迟。如为了避免由于页面错误而引起的延迟，应用程序可能会使用mlock()或mlockall()将其所有虚拟内存锁在RAM中
2. 高优先级进程应该能保持互斥的访问cpu直至他完成或自动释放cpu
3. 实时应用应该能够精确的控制其组件进程的调度顺序

两个实时调度策略
- SCHED_RR
- SCHED_FIFO

以上两个中的任意策略优先级都要高于`标准循环时间分享策略`来调度的进程

在多处理器系统中，各个CPU拥有独立的运行队列（这种方式比使用一个系统层面的运行队列的性能要好），并且每个CPU的运行队列中的进程的优先级都局限于该队列。
> 如假设一个双处理器系统中运行着三个进程，进程A的实时优先级为20，并且它位于CPU0的等待队列中，而该CPU当前正在运行优先级为30的进程B，
> 即使CPU1正在运行优先级为10的进程C，进程A还是需要等待CPU0。

api
//TODO

运作在两个实时调度策略 SCHED_RR（循环）和 SCHED_FIFO（先入先出）下的进
程的优先级总是高于运作在非实时策略下的进程。
运作在 SCHED_FIFO 策略下的进程会互斥地访问 CPU 直到它执行终止或自动释放
CPU 或被进入可运行状态的优先级更高的进程抢占。类似的规则同样适用于 SCHED_RR 策略，
但在该策略下，如果存在多个进程运行于同样的优先级下，那么 CPU 就会以循环的方式被这
些进程共享。

# cpu亲和力
当一个进程在一个多处理器系统上被重新调度时无需在上一次执行的CPU上运行。之所以会在另一个CPU上运行的原因是原来的CPU处于忙碌状态。

进程切换CPU时对性能会有一定的影响：
> 如果在原来的CPU的高速缓冲器中存在进程的数据，那么为了将进程的一行数据加载进新CPU的高速缓冲器中，
> 首先必须使这行数据失效（即在没被修改的情况下丢弃数据，在被修改的情况下将数据写入内存）。
> （为防止高速缓冲器不一致，多处理器架构在某个时刻只允许数据被存放在一个CPU的高速缓冲器中。）
> 这个使数据失效的过程会消耗时间。由于存在这个性能影响，Linux（2.6）内核尝试了给进程保证软CPU亲和力—在条件允许的情况下进程重新被调度到原来的CPU上运行。

有时候需要为进程设置硬CPU亲和力，这样就能显式地将其限制在可用CPU中的一个或一组CPU上运行。之所以需要这样做，原因如下。
- 可以避免由使高速缓冲器中的数据失效所带来的性能影响
- 如果多个线程（或进程）访问同样的数据，那么当将它们限制在同样的CPU上的话可能会带来性能提升，因为它们无需竞争数据并且也不存在由此而产生的高速缓冲器未命中。
- 对于时间关键的应用程序来讲，可能需要为此应用程序预留一个或更多CPU，而将系统中大多数进程限制在其他CPU上

API
//TODO


进程的 CPU 亲和力掩码可以用来将进程限制在多处理器系统上可用 CPU 的子集中运行。
这样就可以提高特定类型的应用程序的性能。